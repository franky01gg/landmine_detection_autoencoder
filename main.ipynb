{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the procedure presented in\n",
    "\n",
    "P. Bestagini, F. Lombardi, M. Lualdi, F. Picetti, S. Tubaro, <i>Landmine Detection Using Autoencoders on Multi-polarization GPR Volumetric Data</i>, Oct. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\mihau\\anaconda3\\envs\\tf_36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import PreProcessing\n",
    "import net\n",
    "from PatchExtractor import PatchExtractor\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = 'giuriati_2/20170621_deg0_HHVV.npy'\n",
    "out_path = 'cnn_article'\n",
    "architecture = 'Auto3D2'\n",
    "ny = 3 # number of adjacent B-scans to be considered\n",
    "data_augmentation = True\n",
    "preprocessing = 'normalize'\n",
    "patch_size = 64\n",
    "patch_stride = 4\n",
    "n_bsc = 5 # number of B_scans for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pp(string):\n",
    "    return getattr(PreProcessing, string)\n",
    "\n",
    "def parse_net(string):\n",
    "    return getattr(net, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "field, campaign = in_path.split('/')\n",
    "campaign, extension = campaign.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = np.load('./datasets/'+str(in_path),allow_pickle=True).item()\n",
    "\n",
    "train_bsc_idx = np.where(np.asarray(dataset['ground_truth']) == 0)[0][:n_bsc]\n",
    "trainset = dataset['data'][train_bsc_idx]\n",
    "trainset = np.moveaxis(trainset, np.argmin(trainset.shape), -1)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### block extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patch_size is not None:\n",
    "    patch_size = (patch_size, patch_size)\n",
    "else:\n",
    "    patch_size = trainset.shape[1:]\n",
    "\n",
    "patch_size = patch_size + (ny,)\n",
    "patch_stride = (patch_stride, patch_stride, 1)\n",
    "\n",
    "pe = PatchExtractor(patch_size, stride=patch_stride)\n",
    "\n",
    "train_patches = pe.extract(trainset)\n",
    "# reshaping\n",
    "train_patches = train_patches.reshape((-1,) + patch_size)\n",
    "\n",
    "# preprocessing each patch\n",
    "train_patches, min_tr, max_tr = PreProcessing.apply_transform(train_patches, transform=parse_pp(preprocessing))\n",
    "\n",
    "# Data augmentation (default=True)\n",
    "if data_augmentation:\n",
    "    train_patches = np.concatenate([train_patches, np.flip(train_patches, axis=2).copy()], axis=0)\n",
    "\n",
    "train_patches = shuffle(train_patches)\n",
    "\n",
    "# create training and validation sets\n",
    "train_patches, val_patches, train_index, val_index = train_test_split(train_patches,\n",
    "                                                                      np.arange(train_patches.shape[0]),\n",
    "                                                                      test_size=0.5,\n",
    "                                                                      random_state=118\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = net.Settings()\n",
    "patience = sets.patience\n",
    "lr_factor = sets.lr_factor\n",
    "batch_size = sets.batch_size\n",
    "epochs = sets.epochs\n",
    "\n",
    "autoencoder, encoder = parse_net(architecture)(patch_size)\n",
    "\n",
    "out_name = field+'_'+campaign+'_'+architecture+'_patch'+str(patch_size[0])+'_stride'+str(patch_stride[0])+'_bsc'+str(n_bsc)+'_ny'+str(ny)\n",
    "\n",
    "lr_chkpt = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=lr_factor,\n",
    "                             patience=patience//2,\n",
    "                             verbose=0,\n",
    "                             mode='auto',\n",
    "                             epsilon=0.0001,\n",
    "                             cooldown=0,\n",
    "                             min_lr=0)\n",
    "save_chkpt = ModelCheckpoint(os.path.join(out_path, out_name+'.h5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')\n",
    "stop_chkpt = EarlyStopping(monitor='val_loss',\n",
    "                           patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "g_in_0 (InputLayer)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "g_conv_0 (Conv2D)            (None, 64, 64, 16)        1744      \n",
      "_________________________________________________________________\n",
      "g_conv_1 (Conv2D)            (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "g_conv_2 (Conv2D)            (None, 16, 16, 16)        4112      \n",
      "_________________________________________________________________\n",
      "g_conv_3 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 16)          1040      \n",
      "_________________________________________________________________\n",
      "encoder (Conv2D)             (None, 2, 2, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 16)          1040      \n",
      "_________________________________________________________________\n",
      "g_deconv_0 (Conv2DTranspose) (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "g_deconv_1 (Conv2DTranspose) (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "g_deconv_2 (Conv2DTranspose) (None, 32, 32, 16)        4112      \n",
      "_________________________________________________________________\n",
      "g_deconv_3 (Conv2DTranspose) (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "g_deconv_4 (Conv2DTranspose) (None, 64, 64, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 32,563\n",
      "Trainable params: 32,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 0.01410, saving model to cnn_article\\giuriati_2_20170621_deg0_HHVV_Auto3D2_patch64_stride4_bsc5_ny3.h5\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "train = autoencoder.fit(train_patches, train_patches,\n",
    "                        validation_data=(val_patches, val_patches),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        callbacks=[save_chkpt, stop_chkpt, lr_chkpt])\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = './cnn_article/giuriati_2_20170621_deg0_HHVV_Auto3D2_patch64_stride4_bsc5_ny3'\n",
    "net_weights = training + '.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case, the dataset for training in the same for testing\n",
    "train_path = in_path\n",
    "dataset = np.load('./datasets/' + str(in_path),allow_pickle=True).item()\n",
    "\n",
    "# preprocessing\n",
    "data = dataset['data']\n",
    "\n",
    "# patch extractor\n",
    "pe = PatchExtractor(patch_size, stride=patch_stride)\n",
    "\n",
    "# background bscans for training\n",
    "gt = np.asarray(dataset['ground_truth'])\n",
    "del dataset\n",
    "\n",
    "test_idx = np.arange(data.shape[0])\n",
    "# check whether the test dataset is the same of the training\n",
    "if in_path == train_path:\n",
    "    train_idx = np.where(gt == 0)[0][:n_bsc]\n",
    "    test_idx = np.delete(test_idx, train_idx)\n",
    "testset = data[test_idx]\n",
    "gt = gt[test_idx]\n",
    "del data\n",
    "testset = np.moveaxis(testset, np.argmin(testset.shape), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = parse_net(architecture)(patch_size)\n",
    "autoencoder.load_weights(os.path.join(net_weights))\n",
    "\n",
    "out_name = field+'_'+campaign+'_'+architecture+'_patch'+str(patch_size[0])+'_stride'+str(patch_stride[0])+'_bsc'+str(n_bsc)+'_ny'+str(ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.9 GiB for an array with shape (151335, 64, 64, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a3971355b9d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpatches_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmseFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmseFeat_patches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmseFeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mpatches_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.9 GiB for an array with shape (151335, 64, 64, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "patches = pe.extract(testset)\n",
    "del testset\n",
    "patchesIdx = patches.shape\n",
    "patches_hat = autoencoder.predict(patches.reshape((-1,) + patch_size))\n",
    "mseFeat = (encoder.predict(patches.reshape((-1,) + patch_size)) - encoder.predict(patches_hat))**2\n",
    "mseFeat_patches = np.zeros(patches_hat.shape) + np.mean(mseFeat, axis=(1,2,3)).reshape((-1,1,1,1))\n",
    "del patches\n",
    "del patches_hat\n",
    "del mseFeat\n",
    "mseFeat_vol = pe.reconstruct(mseFeat_patches.reshape(patchesIdx))\n",
    "del mseFeat_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mseFeat_vol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e7271f49cf8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmse_mask_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmseFeat_vol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfpr_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_mask_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mroc_auc_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_mask_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best AUC = %0.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mroc_auc_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mseFeat_vol' is not defined"
     ]
    }
   ],
   "source": [
    "mse_mask_max = np.max(mseFeat_vol, axis=(0, 1))\n",
    "fpr_max, tpr_max, thresholds_max = roc_curve(gt, mse_mask_max)\n",
    "roc_auc_max = roc_auc_score(gt, mse_mask_max)\n",
    "print('best AUC = %0.2f' % roc_auc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
